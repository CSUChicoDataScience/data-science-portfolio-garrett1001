---
title: "CSCI 385 - Second Deliverable"
author: "Garrett Welton"
date: "11/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(RSocrata)
library(tidyverse)
library(modelr)
library(caret)
library(class)
```

## Predictions

Based upon my initial discovery and exploration I would like to predict the presence of heart disease in hospital patients from their medical data.

## "Success" and "Failure"

For the predictions I am trying to make "Success" would be creating a model that accurately predicts the target variable or the presence of heart disease in a patient with more than 70%. "Failure" would be if my model was unable to accurately predict this.

## New Data

My additional dataset is the "National Health Interview Survey (NHIS) - National Cardiovascular Disease Surveillance Data" published by the Centers for Disease Control and Prevention. The NHIS monitors the health of the nation through personal household interviews. This dataset is provided by the National Cardiovascular Disease Surveillance System, which is designed to integrate multiple indicators from many data sources to provide a comprehensive picture of the public health burden of CVDs and associated risk factors in the United States. This data is from 2001 and forward. This dataset should be useful for determining how different regions of the US affect the rate of cardiovascular disease within its different populations, as well as how different risk factors play into these rates. This new data will help me help me be able to make new and better predictions.

```{r}
#API call
df <- read.socrata(
  "https://chronicdata.cdc.gov/resource/fwns-azgu.csv",
  app_token = "OJxxBUd1kEfoUDA5ACIVnD88u"
)
```

Tidying Data:

```{r}
NHIS <- filter(df, !is.na(data_value), data_value_type == "Age-Standardized" | break_out_category == "Age") %>%
  select(year, locationdesc, category, topic, data_value, break_out_category, break_out) %>%
  rename(location = locationdesc, percent_value = data_value)
```

I first filtered the data to get rid of any NA values and any non-age-standardized data, that was not a part of the age break_out_category. Then I used select to get rid of the unneeded columns. Finally I renamed some columns to make it clear what they are.

```{r}
cardioDiseases <- filter(NHIS, category == "Cardiovascular Diseases") %>%
  select(-category)

riskFactors <- filter(NHIS, category != "Cardiovascular Diseases") %>%
  select(-category)

head(cardioDiseases)

head(riskFactors)

cardioDiseases <- cardioDiseases %>%
  pivot_wider(names_from = c(break_out_category, break_out),
              values_from = percent_value)

colSums(is.na(cardioDiseases))

cardioDiseases <- select(cardioDiseases, -`Age_25-44`, -`Age_18-24`, -Race_Other, -`Race_Non-Hispanic Asian`) %>%
  drop_na()

unique(cardioDiseases$topic)
  
cardioDiseases.majorCardiovascularDisease <- filter(cardioDiseases, topic == "Major Cardiovascular Disease") %>%
  select(-topic)
cardioDiseases.heartAttack <- filter(cardioDiseases, topic == "Acute Myocardial Infarction (Heart Attack)") %>%
  select(-topic)
cardioDiseases.coronaryHeartDisease <- filter(cardioDiseases, topic == "Coronary Heart Disease") %>%
  select(-topic)
cardioDiseases.stroke <- filter(cardioDiseases, topic == "Stroke") %>%
  select(-topic)

riskFactors <- riskFactors %>%
  pivot_wider(names_from = c(break_out_category, break_out),
              values_from = percent_value,
              values_fn = mean)

colSums(is.na(riskFactors))

riskFactors <- select(riskFactors, -Race_Other, -`Race_Non-Hispanic Asian`) %>%
  drop_na()

riskFactors.physicalInactivity <- filter(riskFactors, topic == "Physical Inactivity") %>%
  select(-topic)
riskFactors.smoking <- filter(riskFactors, topic == "Smoking") %>%
  select(-topic)
riskFactors.hypertension <- filter(riskFactors, topic == "Hypertension") %>%
  select(-topic)
```

I tried multiple methods to tidy my new data, however, the structure of the data seems to be a standard of the CDC and proved to be a challenge. Most of the publicly available datasets I found on cardiovascular disease were published by the CDC and shared this same format. The data contains many nested variable within its column variables, making it not tidy. The challenge is that most of the variable within these column are dependent on variables that are stored with other columns. Due to this I couldn't find a nice way to tidy the data. I tried splitting the data into multiple tables, but believe this can make working with the data more of a challenge.

## Tables

```{r}
head(NHIS)
```

* `year` - `integer` - year the data was collected.
* `location` - `character` - categorical variable containing the region of the US that the data was collected. (United States; Northeast; Midwest; South; West)
* `category` - `character` - variable describing the the category of the topic variable. (Cardiovascular Diseases, Risk Factor)
* `topic` - `character` - categorical variable describing the topic that the percent_value corresponds to. (Major Cardiovascular Disease; Acute Myocardial Infarction (Heart Attack); Coronary Heart Disease; Stroke; Physical Inactivity; Smoking; Hypertension)
* `percent_value` - `double` - the percent of the beak_out variable where topic variable is true. All values besides those that correspond to the "Age" break_out_category have been age-Standardized between different regions.
* `break_out_category` - `character` - variable describing the category of the beak_out variable (Overall; Gender; Age; Race)
* `break_out` - `character` - the group within the break_out_category that the percent_value corresponds to. (Overall; Male; Female; 25-44; 45-64; 65+; 35+; 75+; Non-Hispanic White; Non-Hispanic Black; Non-Hispanic Asian; Other)

```{r}
Heart <- read.csv("heart.csv")
head(Heart)
```

## Simple Model

My main goal is to be able to predict the presents of heart disease in patients based on different risk factors. To do this I will use classification to determine if a patient belongs to the healthy heart group or the unhealthy group. I will use K-Nearest neighbors to do this classification.

Model Version 1:
```{r}
heart <- as_tibble(Heart) %>%
  select(-target)

set.seed(131)

#Split training and test dataset
train_rows <- as.vector(createDataPartition(Heart$target, p = 0.8, list = FALSE))

train <- heart[train_rows, ]
test <- heart[-train_rows, ]
train.def <- Heart[train_rows, 14]
test.def <- Heart[-train_rows, 14]

knn.3 <- knn(train, test, train.def, k = 3)
knn.5 <- knn(train, test, train.def, k = 5)
knn.7 <- knn(train, test, train.def, k = 7)
knn.15 <- knn(train, test, train.def, k = 15)

#function that divides the correct predictions by total number of predictions that tell us how accurate the model is.
get.accuracy <- function(x){sum(diag(x)/(sum(rowSums(x))))} 

tab.3 <- table(knn.3, test.def)
confusionMatrix(tab.3)
acc3 <- get.accuracy(tab.3)
#K = 3 correctly classifies 78.05% of the outcomes

tab.5 <- table(knn.5, test.def)
confusionMatrix(tab.5)
acc5 <- get.accuracy(tab.5)
#K = 5 correctly classifies 73.66% of the outcomes

tab.7 <- table(knn.7, test.def)
confusionMatrix(tab.7)
acc7 <- get.accuracy(tab.7)
#K = 7 correctly classifies 79.51% of the outcomes

tab.15 <- table(knn.15, test.def)
confusionMatrix(tab.15)
acc15 <- get.accuracy(tab.15)
#K = 15 correctly classifies 80% of the outcomes

k <- c(3, 5, 7, 15)
Accuracy <- c(acc3, acc5, acc7, acc15)
df <- data.frame(k, Accuracy)

#Accuracy plot
ggplot(df, aes(x=k, y=Accuracy)) +
  geom_point() +
  geom_line()
```

Model Version 2:
```{r}
heart <- as_tibble(Heart) %>%
  select(-target, -ca, -trestbps)

set.seed(131)

#Split training and test dataset
train_rows <- as.vector(createDataPartition(Heart$target, p = 0.8, list = FALSE))

train <- heart[train_rows, ]
test <- heart[-train_rows, ]
train.def <- Heart[train_rows, 14]
test.def <- Heart[-train_rows, 14]

knn.3 <- knn(train, test, train.def, k = 3)
knn.5 <- knn(train, test, train.def, k = 5)
knn.7 <- knn(train, test, train.def, k = 7)
knn.15 <- knn(train, test, train.def, k = 15)

#function that divides the correct predictions by total number of predictions that tell us how accurate the model is.
get.accuracy <- function(x){sum(diag(x)/(sum(rowSums(x))))} 

tab.3 <- table(knn.3, test.def)
confusionMatrix(tab.3)
acc3 <- get.accuracy(tab.3)
#K = 3 correctly classifies 78.54% of the outcomes

tab.5 <- table(knn.5, test.def)
confusionMatrix(tab.5)
acc5 <- get.accuracy(tab.5)
#K = 5 correctly classifies 77.56% of the outcomes

tab.7 <- table(knn.7, test.def)
confusionMatrix(tab.7)
acc7 <- get.accuracy(tab.7)
#K = 7 correctly classifies 81.46% of the outcomes

tab.15 <- table(knn.15, test.def)
confusionMatrix(tab.15)
acc15 <- get.accuracy(tab.15)
#K = 15 correctly classifies 80.98% of the outcomes

k <- c(3, 5, 7, 15)
Accuracy <- c(acc3, acc5, acc7, acc15)
df <- data.frame(k, Accuracy)

#Accuracy plot
ggplot(df, aes(x=k, y=Accuracy)) +
  geom_point() +
  geom_line()
```

## Parameters and Output

In the first version of my model, my parameters were all variables except the target and my best output was 80% accuracy. I choose to use all variables because the variable provided in the dataset are a collection of some of the best indicators of heart diseases, so it would make sense to use them all. The percent of success was a bit lower then I hoped for, so I decided to try another version where I removed some variables based on my data exploration from the first deliverable. For this version I removed the variables 'ca' and 'trestbps' from my parameters. The reason I removed 'trestbps' or resting blood pressure was because the distribution between the two groups in my first deliverable was very similar. This seemed to improve my model raising my best output to 81.46% accuracy. The biggest limitation to this model is my lack of knowledge and experience using k nearest neighbor, for example I am unsure how I could create a visualization for this algorithm.

## Social and Ethical Implications

A positive social impact of this model is to reduce possible deaths on a global scale, since heart disease is the number one cause of death world wide. One possible ethical impact is the possibility of this model being used by companies such as private health insurance companies to determine whether or not to cover or raise prices on individuals who may be at risk of heart disease.
